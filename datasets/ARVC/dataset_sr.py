from torchvision import transforms
import numpy as np
from _collections import defaultdict
from datasets.ACDC.data4d_simple import ACDCDataset4DPairs, MyToTensor
from datasets.ACDC.acdc_transforms import ToTensor, CenterCrop, RandomAnyRotation
from datasets.ACDC.acdc_transforms import RandomRotation
from datasets.ARVC.dataset import ARVCImage, do_limit_load
from tqdm import tqdm
from datasets.data_config import get_config
from datasets.common import get_arvc_datasets


arvc_data_settings = get_config('ARVC')


def get_arvc_4d_image_array(dataset, rescale=True, resample=False, limited_load=False, new_spacing=None):
    assert dataset in arvc_data_settings.datasets
    abs_file_list = get_arvc_datasets()[dataset]
    if limited_load:
        abs_file_list = do_limit_load(abs_file_list)
    abs_file_list.sort()
    image_list = {}
    # IMPORTANT: actually the abs_file_list contains for each patient a tuple (filename, patient_idx (integer))
    # we did this because the patient_ids contain alphanumeric characters
    for abs_filename, pat_num in tqdm(abs_file_list, desc='Load ARVC {}'.format(dataset), total=len(abs_file_list)):
        img = ARVCImage(abs_filename, filename_ref_labels=None, rescale=rescale, resample=resample,
                        new_spacing=new_spacing, pat_num=pat_num)
        image4d_dict = img.preprocessed4d()
        image_list[pat_num] = image4d_dict
    return image_list


def get_arvc_sr_dataset(args, rs, sets="both", new_spacing=None, transform_tr=None,
                         transform_te=None, test_limited_load=True, resample=True):

    training_set = None
    val_set = None
    if transform_tr is None:
        transform_tr = transforms.Compose([CenterCrop(args['width']), RandomRotation(rs=rs),
                                                                         MyToTensor()])
    if transform_te is None:
        transform_te = transforms.Compose([CenterCrop(args['width']), MyToTensor()])
    if sets in ['both', 'train']:
        training_set = ARVCDataset4DPairs('training',
                                           resample=resample,
                                           transform=transform_tr,
                                           limited_load=args['limited_load'],
                                          new_spacing=new_spacing)
    if sets in ['both', 'test']:
        val_set = ARVCDataset4DPairs('validation',
                                      resample=resample,
                                      transform=transform_te,
                                      limited_load=test_limited_load,
                                     new_spacing=new_spacing)
    return training_set, val_set


class ARVCDataset4DPairs(ACDCDataset4DPairs):

    """
            Parameter adjacency:

            Random in this context means that "paired_image" only contains one image slice and not TWO which is the case in
            "paired" and "combined" mode. The Pytorch dataloader will create batches with size 1 in dimension 1, whereas in the
            other modes it will return size 2 in dimension 1. We use the function "prepare_batch_pairs" to reshuffle the batches
            so that slices for interpolation will be generated by splitting the batch into two halves. Hence, in those cases the
            batch size doubles to batch_size * 2. In random mode the batch size stays the same and for interpolation the batch is
            just splitted.
    """

    def __init__(self, dataset,  # ['training', 'validation', 'test']
                 images4d=None,
                 transform=None, limited_load=False,
                 rescale=True,
                 resample=False, rs=np.random.RandomState(1234),
                 new_spacing=None):
        self.rs = rs
        self.transform = transform
        self._resample = resample
        self.dataset = dataset
        self.z_spacings = defaultdict(list)
        if images4d is None:
            self.images4d = get_arvc_4d_image_array(dataset, rescale=rescale, resample=resample, limited_load=limited_load,
                                                    new_spacing=new_spacing)
        else:
            self.images4d = images4d

        self._get_indices()
        print("INFO - ARVCDataset4DPairs - unique z-spacings ", self.z_spacings.keys())
