import numpy as np
import os
from torch.utils.data import Dataset
from torchvision import transforms
from tqdm import tqdm, tqdm_notebook
from kwatsch.common import isnotebook
from datasets.ACDC.data import get_patids_acdc_sr, ACDCImage
from tqdm import tqdm
from collections import OrderedDict, defaultdict
from datasets.ACDC.data4d_simple import apply_transform, get_random_adjacent_slice, MyToTensor
from datasets.ACDC.acdc_transforms import CenterCrop, RandomAnyRotation


def get_dataset_acdc_with_lables(args, dta_settings, rs, acdc_set="both", new_spacing=None, transform_tr=None,
                                 transform_te=None, test_limited_load=True,):
    training_set = None
    val_set = None
    if transform_tr is None:
        transform_tr = transforms.Compose([CenterCrop(args['width']), RandomAnyRotation(rs=rs, max_degree=359),
                                                                         MyToTensor()])
    if transform_te is None:
        transform_te = transforms.Compose([CenterCrop(args['width']), MyToTensor()])
    if acdc_set in ['both', 'train']:
        training_set = ACDCDatasetEDESPairs('training',
                                           root_dir=dta_settings.short_axis_dir,
                                           resample=True,
                                           transform=transform_tr,
                                           limited_load=args['limited_load'],
                                          slice_selection=args['slice_selection'],
                                          new_spacing=new_spacing,
                                          rs=rs)
    if acdc_set in ['both', 'test']:
        val_set = ACDCDatasetEDESPairs('validation',
                                      root_dir=dta_settings.short_axis_dir,
                                      resample=True,
                                      transform=transform_te,
                                      limited_load=test_limited_load,
                                     slice_selection=args['slice_selection'],
                                     new_spacing=new_spacing,
                                     rs=rs)
    return training_set, val_set


def get_4d_edes_image_array(root_dir, dataset=None, rescale=True, resample=False, limited_load=False, new_spacing=None,
                            rs=np.random.RandomState(1234), pat_nums=None,
                            transform=None):
    # pat_nums: list of integers
    root_dir = os.path.expanduser(root_dir)
    print("WARNING - get_4d_edes_image_array - Loading ACDCWithLabels data from {}".format(root_dir))
    assert (dataset is None and pat_nums is not None) or (dataset is not None and pat_nums is None)
    if pat_nums is None:
        pat_nums = get_patids_acdc_sr(dataset, rs=rs, limited_load=limited_load, max_limit_load=2)
        load_info = 'Load {} set'.format(dataset)
    else:
        load_info = "Loading {} patients".format(len(pat_nums))

    pat_nums.sort()
    dataset_dict = OrderedDict()

    if isnotebook():
        myiterator = tqdm_notebook(pat_nums, desc=load_info, total=len(pat_nums))
    else:
        myiterator = tqdm(pat_nums, desc=load_info, total=len(pat_nums))
    for patnum in myiterator:
        img = ACDCImage(patnum, root_dir=root_dir, resample=resample, scale_intensities=rescale,
                        abs_filename=None, new_spacing=new_spacing)
        ed_image, sp, ed_labels = img.ed()
        es_image, _, es_labels = img.es()
        frame_id_ed = img.get_frame_id('ED')
        frame_id_es = img.get_frame_id('ES')
        img4d = np.concatenate((ed_image[None], es_image[None]), axis=0)
        label4d = np.concatenate((ed_labels[None], es_labels[None]), axis=0)
        image4d_dict = {'image': img4d, 'spacing': img.spacing, 'patient_id': img.patient_id, "num_frames": 2,
                        'labels': label4d,
                        'original_spacing': img.original_spacing, 'num_slices': ed_image.shape[0],
                        'orig_num_frames': 2}
        dataset_dict[patnum] = image4d_dict
    if transform is not None:
        dataset_dict = apply_transform(dataset_dict, transform)
    return dataset_dict


class ACDCDatasetEDESPairs(Dataset):

    """
            Parameter adjacency:

            Random in this context means that "paired_image" only contains one image slice and not TWO which is the case in
            "paired" and "combined" mode. The Pytorch dataloader will create batches with size 1 in dimension 1, whereas in the
            other modes it will return size 2 in dimension 1. We use the function "prepare_batch_pairs" to reshuffle the batches
            so that slices for interpolation will be generated by splitting the batch into two halves. Hence, in those cases the
            batch size doubles to batch_size * 2. In random mode the batch size stays the same and for interpolation the batch is
            just splitted.
    """

    def __init__(self, dataset,  # ['training', 'validation', 'full', 'test']  test: only applicable for SR
                 images4d=None,
                 root_dir='~/data/ACDC/all_cardiac_phases',
                 transform=None, limited_load=False,
                 rescale=True,
                 resample=False,
                 slice_selection="adjacent_plus",
                 new_spacing=None, rs=np.random.RandomState(1234)):
        assert slice_selection in ['adjacent', 'adjacent_plus', 'mix']
        self._root_dir = root_dir
        self.transform = transform
        self._resample = resample
        self.slice_selection = slice_selection
        self.dataset = dataset
        self.z_spacings = defaultdict(list)
        self.rs = rs
        if images4d is None:
            self.images4d = get_4d_edes_image_array(root_dir, dataset, rescale=rescale, resample=resample, limited_load=limited_load,
                                                    new_spacing=new_spacing, rs=rs)
        else:
            self.images4d = images4d
        self._get_indices()
        # print("INFO - ACDCDataset4DPairs - unique z-spacings ", self.z_spacings.keys())

    def _get_indices(self):
        allidcs = np.empty((0, 4), dtype=int)
        for patnum, image_dict in self.images4d.items():
            num_frames = image_dict['num_frames']
            num_slices = image_dict['num_slices']
            self.z_spacings[image_dict['spacing'][0]].append("patient_id{:03d}".format(patnum))
            # JS changed 01-07: slice_to and slice_from have length num_slices - 2
            # img_nbr = np.repeat(patnum, num_frames * num_slices)
            img_nbr = np.repeat(patnum, num_frames * num_slices)
            frame_range = np.arange(0, num_frames)
            frame_range = np.tile(frame_range, num_slices)
            slice_range = np.arange(0, num_slices)
            slice_range = np.repeat(slice_range, num_frames)
            slice_max_num = np.repeat(num_slices, num_frames * num_slices)
            allidcs = np.vstack((allidcs, np.vstack((img_nbr, frame_range, slice_range, slice_max_num)).T))

        self._idcs = allidcs.astype(int)

    def __len__(self):
        return len(self._idcs)

    def __getitem__(self, idx):
        patnum, frame_idx_from, slice_id_1, num_slices = self._idcs[idx]
        f, s, _, _ = self.images4d[patnum]['image'].shape
        # Lazy copying from ACDCDataset4DPairs. We don't need this because we only 2 time frames. but
        # we keep this to not adjust other places where this dict key is still required
        # For pat 15, 34, 45 due to voxel intensity errors we skip frames 20-29. But we need original num_frames
        # as feature for alpha_probe network
        orig_num_frames = self.images4d[patnum]['orig_num_frames']
        slice_step = self._get_slice_step()
        slice_id_2 = get_random_adjacent_slice(slice_id_1, num_slices, rs=self.rs, step=slice_step)
        inbetween_slice_id, is_inbetween = self._get_inbetween_sliceid(slice_id_1, slice_id_2)
        if self.rs.choice([0, 1]) == 0:
            slice_idx_from, slice_idx_to = slice_id_1, slice_id_2
        else:
            slice_idx_from, slice_idx_to = slice_id_2, slice_id_1
        # for backward compatibility
        loss_mask = np.array([1]).astype(np.float32)
        # print("slice IDs ", s, slice_idx_from, inbetween_slice_id, slice_idx_to)
        try:
            paired_image = np.vstack((np.expand_dims(self.images4d[patnum]['image'][frame_idx_from][slice_idx_from], 0),
                                      np.expand_dims(self.images4d[patnum]['labels'][frame_idx_from][slice_idx_from], 0),
                                      np.expand_dims(self.images4d[patnum]['image'][frame_idx_from][slice_idx_to], 0),
                                      np.expand_dims(self.images4d[patnum]['labels'][frame_idx_from][slice_idx_to], 0),
                                      np.expand_dims(self.images4d[patnum]['image'][frame_idx_from][inbetween_slice_id], 0),
                                      np.expand_dims(self.images4d[patnum]['labels'][frame_idx_from][inbetween_slice_id],
                                                     0)
                                      ))

        except:
            raise ValueError(self.images4d[patnum]['patient_id'], idx, frame_idx_from, f,
                             self.images4d[patnum]['image'].shape, "mix slice id {}".format(inbetween_slice_id))

        num_slices = self.images4d[patnum]['num_slices']
        # if self.dataset == 'training':
        #    print("ACDCDataset4DPairs ", self.dataset, idx, patnum, frame_idx_from, slice_idx_from, slice_idx_to)
        sample = {'image': paired_image.astype(np.float32),
                  'num_slices_vol': np.array([num_slices]).astype(np.float32),
                  'num_frames_vol': np.array([orig_num_frames]).astype(np.float32),
                  'slice_id_from': np.array([slice_idx_from]).astype(np.float32),
                  'slice_id_to': np.array([slice_idx_to]).astype(np.float32),
                  'spacing': self.images4d[patnum]['spacing'],
                  'frame_id_from': np.array([frame_idx_from]).astype(np.float32),
                  'frame_id_to': np.array([frame_idx_from]).astype(np.float32),
                  'patient_id': np.array([patnum]).astype(np.int),
                  'original_spacing': self.images4d[patnum]['original_spacing'],
                  'is_inbetween': np.float32(is_inbetween),
                  'loss_mask': loss_mask}

        if self.transform:
            sample = self.transform(sample)

        return sample

    def set_transform(self, transform):
        self.transform = transform

    def _get_slice_step(self):
        if self.slice_selection == "adjacent":
            return 1
        elif self.slice_selection == "adjacent_plus":
            return 2
        elif self.slice_selection == "mix":
            return self.rs.choice([1, 2])

    @staticmethod
    def _get_inbetween_sliceid(sliceid1, sliceid2):
        if (sliceid1 + sliceid2) % 2 == 0:
            # gap between slice ids is one.
            in_between_sliceid = (sliceid1 + sliceid2) // 2
            is_inbetween = 1
        else:
            in_between_sliceid = sliceid1
            is_inbetween = 0
        return in_between_sliceid, is_inbetween


def get_4d_edes_image_generator(root_dir, dataset=None, rescale=True, resample=False, limited_load=False, new_spacing=None,
                                rs=np.random.RandomState(1234), pat_nums=None):
    # pat_nums: list of integers
    root_dir = os.path.expanduser(root_dir)
    # print("WARNING - get_4d_edes_image_array - Loading ACDCWithLabels data from {}".format(root_dir))
    assert (dataset is None and pat_nums is not None) or (dataset is not None and pat_nums is None)
    if pat_nums is None:
        pat_nums = get_patids_acdc_sr(dataset, rs=rs, limited_load=limited_load, max_limit_load=2)
        load_info = 'Load {} set'.format(dataset)
    else:
        load_info = "Loading {} patients".format(len(pat_nums))
    if isnotebook():
        myiterator = tqdm_notebook(pat_nums, desc=load_info, total=len(pat_nums))
    else:
        myiterator = tqdm(pat_nums, desc=load_info, total=len(pat_nums))
    pat_nums.sort()
    for patnum in myiterator:
        img = ACDCImage(patnum, root_dir=root_dir, resample=resample, scale_intensities=rescale,
                        abs_filename=None, new_spacing=new_spacing)
        ed_image, sp, ed_labels = img.ed()
        es_image, _, es_labels = img.es()
        frame_id_ed = img.get_frame_id('ED')
        frame_id_es = img.get_frame_id('ES')
        yield {'image': ed_image, 'spacing': img.spacing, 'patient_id': img.patient_id, "num_frames": 2,
                        'labels': ed_labels, 'cardiac_phase': 'ED', 'frame_id': 0,
                        'original_spacing': img.original_spacing, 'num_slices': ed_image.shape[0],
                        'orig_num_frames': 2}
        yield {'image': es_image, 'spacing': img.spacing, 'patient_id': img.patient_id, "num_frames": 2,
               'labels': es_labels, 'cardiac_phase': 'ES', 'frame_id': 1,
               'original_spacing': img.original_spacing, 'num_slices': ed_image.shape[0],
               'orig_num_frames': 2}


def get_4d_image_generator(root_dir, dataset=None, rescale=True, resample=False, limited_load=False, new_spacing=None,
                                rs=np.random.RandomState(1234), pat_nums=None):
    # pat_nums: list of integers
    root_dir = os.path.expanduser(root_dir)
    # print("WARNING - get_4d_edes_image_array - Loading ACDCWithLabels data from {}".format(root_dir))
    assert (dataset is None and pat_nums is not None) or (dataset is not None and pat_nums is None)
    if pat_nums is None:
        pat_nums = get_patids_acdc_sr(dataset, rs=rs, limited_load=limited_load, max_limit_load=2)
        load_info = 'Load {} set'.format(dataset)
    else:
        load_info = "Loading {} patients".format(len(pat_nums))
    if isnotebook():
        myiterator = tqdm_notebook(pat_nums, desc=load_info, total=len(pat_nums))
    else:
        myiterator = tqdm(pat_nums, desc=load_info, total=len(pat_nums))
    pat_nums.sort()
    for patnum in myiterator:
        img = ACDCImage(patnum, root_dir=root_dir, resample=resample, scale_intensities=rescale,
                        abs_filename=None, new_spacing=new_spacing)
        img4d_dict = img.preprocessed4d()
        for frame_id in np.arange(img4d_dict['num_frames']):
            dummy_labels = np.zeros_like(img4d_dict['image'][frame_id]).astype(np.int)
            yield {'image': img4d_dict['image'][frame_id], 'spacing': img.spacing, 'patient_id': img.patient_id,
                   "num_frames": 1,
                   'labels': dummy_labels, 'cardiac_phase': str(frame_id), 'frame_id': frame_id,
                    'original_spacing': img4d_dict['original_spacing'], 'num_slices': img4d_dict['num_slices'],
                    'orig_num_frames': img4d_dict['original_spacing']}
